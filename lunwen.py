# -*- coding: utf-8 -*-
"""lunwen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GZtWZAF1A_T-wJl0NS-6IpmsVwXH-KXL
"""

import torch.nn as nn
import torch
import torch.optim as optim
import csv
import pandas as pd
import os
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from torchvision import transforms
from torch.utils.tensorboard import SummaryWriter
import math
import ast
import torch.utils.model_zoo as model_zoo
# 引入文件

# @title 示例，创建一个csv文件，不需要执行
# 示例，创建一个csv文件，不需要执行

# 定义CSV文件的列名
headers = ['Frame', 'speed', 'yaw', 'acceletation']

# 生成10行示例数据
data = [
    ['张三', 25, 2, 12000],
    ['李四', 30, 3, 18000],
    ['王五', 22, 4, 3000],
    ['赵六', 45, 5, 25000],
    ['钱七', 35, 6, 9000],
    ['孙八', 28, 7, 15000],
    ['周九', 50, 8, 50000],
    ['吴十', 26, 9, 13000],
    ['郑十一', 38, 10, 10000],
    ['冯十二', 29, 11, 11000]
]

# 指定CSV文件路径
csv_file = 'sample_data.csv'

# 写入CSV文件
with open(csv_file, 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)

    # 写入表头
    writer.writerow(headers)

    # 写入数据
    writer.writerows(data)

print(f'CSV文件已生成: {csv_file}')

# @title 展示pd库的使用方式
# dataset的序列
# [1,2,3,4,[0,1,2,3,4,5,6,7],[0,1,2,3,4,5,6,7],[0,1,2,3,4,5,6,7]]

# 创建空 DataFrame，指定列名
df = pd.DataFrame(columns=['frame', 's', 'y', 'a', 'ss', 'yy', 'aa'])

# 方式2：逐行添加（使用字典+pd.concat）
new_row = {
    'frame': 3,
    's': 6,
    'y': 9,
    'a': 12,
    'ss': [2,3,4,5,6,7,8,9],
    'yy': [2,3,4,5,6,7,8,9],
    'aa': [2,3,4,5,6,7,8,9]}
# 将字典转换为 DataFrame 并与原 DataFrame 连接
df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

print(df)

print(df['ss'].dtype)
print("'ss' 列第一个元素的类型:", type(df['ss'][0]))
# 查看 'ss' 列第一个元素中第一个值的类型（应为 'int'）
print("'ss' 列第一个元素中第一个值的类型:", type(df['ss'][0][0]))
data_list = df['ss'][0]
print(data_list, type(data_list))

# @title 创建新的csv文件


# 这里是选择前八帧的速度和转角
def add_time(index, data):
    yaws = []
    speeds = []
    accels = []
    # if index+1:
    for i in range(8):
        add_index = max(0, index - i)  # 确保索引不小于0
        sp = data[add_index]['speed']
        ya = data[add_index]['yaw']
        acc = data[add_index]['accel']
        speeds.append(sp)
        yaws.append(ya)
        accels.append(acc)
    speeds.reverse()
    yaws.reverse()
    accels.reverse() # 保存的结果[8，7，6......0]9组数据
    return speeds, yaws, accels

# 设置转角，加速度，速度

# 数据处理，将原始的csv转变为新的csv
csv_dir = "/content/drive/MyDrive/Colab Notebooks/center_train/center.csv"
img_dir = ""
control_df = pd.DataFrame(columns=['frame', 'speed_now', 'yaw_now', 'accel_now', 'speed_ago', 'yaw_ago', 'accel_ago'])
# 需要保存的格式 : [1,2,3,4,[0,1,2,3,4,5,6,7],[0,1,2,3,4,5,6,7],[0,1,2,3,4,5,6,7]]
data = []
csv_frame = []
csv_speed = []
csv_yaw = []
csv_accel = []
with open(csv_dir, newline='') as f:
  reader = csv.DictReader(f)
  for row in reader:
    csv_frame = str(row['Frame'])
    csv_speed = float(row['speed'])
    csv_yaw = float(row['yaw'])
    csv_accel = float(row['A'])
    data.append({'Frame':csv_frame, 'speed':csv_speed, 'yaw':csv_yaw, 'accel':csv_accel})
  for i in range(len(data)):
      frame = data[i]['Frame']
      speed_now = data[i]['speed']
      yaw_now = data[i]['yaw']
      accel_now = data[i]['accel']
      speeds_ago, yaws_ago, accels_ago = add_time(i-1, data)
      new_row = {'frame': frame,
            'speed_now':speed_now,
            'yaw_now':yaw_now,
            'accel_now':accel_now,
            'speed_ago':speeds_ago,
            'yaw_ago':yaws_ago,
            'accel_ago':accels_ago}
      control_df = pd.concat([control_df, pd.DataFrame([new_row])], ignore_index=True)
print(control_df)

# 保存为csv文件
control_df.to_csv('data.csv',
          index=False,          # 不保存行索引
          encoding='utf-8-sig', # 支持中文
          sep=',',              # 分隔符，默认为逗号
          na_rep='nan')         # NaN 值的表示方式

# 保存为 JSON（每行一个对象）
control_df.to_json('data.json',
           orient='records',  # 按行保存
           lines=True,        # 每行一个 JSON 对象
           force_ascii=False) # 支持非 ASCII 字符

# @title 定义dataset
image_transforms = transforms.Compose([
    transforms.Resize((64, 64)),  # 调整图像大小，不改变通道数
    transforms.ToTensor()])          # 转换为张量
class myDataSet(Dataset):
    def __init__(self, img_dir, csv_dir, transform):
        """
        :param data_dir: 数据文件路径
        :param label_dir: 标签文件路径
        :param transform: transform操作
        """
        self.img_dir = img_dir
        self.csv_dir = csv_dir
        self.transform = transform
        self.data = []    # 创建一个空列表用来保存处理后的数据
        # 读文件夹下每个数据文件名称
        # os.listdir读取指定路径下的所有文件和目录，返回一个包含路径下所有文件和目录名称的列表

        # 读csv标签文件夹下的数据名称
        self.data = []  # 创建一个空列表用来保存字典类型
        with open(csv_dir, newline='',  encoding='utf-8-sig') as f:
            reader = csv.DictReader(f, skipinitialspace=True)
            print("CSV列名:", reader.fieldnames)  # 打印实际列名
            self.data = list(reader)
    def __len__(self):
        return len(self.data)
    def __getitem__(self, index):
        # 获取每一个数据
        # for row in self.data:
        row = self.data[index]
        frame = str(row['frame'])
        frame = str(row['frame'].strip())
        speed_now = float(row['speed_now'].strip())
        yaw_now = float(row['yaw_now'].strip())
        accel_now = float(row['accel_now'].strip())

        # 转换历史数据（使用ast.literal_eval安全解析字符串列表）
        # speed_ago = list(row['speed_ago'].strip())
        # yaw_ago = list(row['yaw_ago'].strip())
        # accel_ago = list(row['accel_ago'].strip())
        speed_ago = ast.literal_eval(row['speed_ago'].strip())
        yaw_ago = ast.literal_eval(row['yaw_ago'].strip())
        accel_ago = ast.literal_eval(row['accel_ago'].strip())

        speed_now = torch.tensor(speed_now)
        yaw_now = torch.tensor(yaw_now)
        accel_now = torch.tensor(accel_now) # 目标信息

        speed_ago = torch.tensor(speed_ago)
        yaw_ago = torch.tensor(yaw_ago)
        accel_ago = torch.tensor(accel_ago) # 时间序列

        img_path = os.path.join(self.img_dir, f'{frame}')
        try:
            img = Image.open(img_path).convert('RGB')
        except FileNotFoundError:
            raise FileNotFoundError(f"图像文件 {img_path} 未找到")

        if self.transform:
            img = self.transform(img)
        # 编码信息，这里提供cat连接：speed_encode, ccel_encode, yaw_encode
        speed_encode = torch.tensor([0,0,0,1,0,0,1,0])
        accel_encode = torch.tensor([0,0,1,0,0,1,0,0])
        yaw_encode = torch.tensor([0,1,0,0,1,0,0,0])
        speed_ago = torch.cat([speed_ago, speed_encode])
        accel_ago = torch.cat([accel_ago, accel_encode])
        yaw_ago = torch.cat([yaw_ago, yaw_encode])

        return img, speed_now, yaw_now, accel_now, speed_ago, yaw_ago, accel_ago  # 返回数据和标签

csv_data_ldir = "data.csv"
photo_data_ldir = "/content/drive/MyDrive/Colab Notebooks/center_train/center_img"
dataset = myDataSet(photo_data_ldir, csv_data_ldir, transform=image_transforms) # 这里只调用了__init__方法
train_dataloader = DataLoader(dataset, batch_size=128, shuffle=True)   # 这里调用了__len__方法
for img, speed_now, yaw_now, accel_now, speed_ago, yaw_ago, accel_ago in train_dataloader:
    print("Image shape:", img.shape)        # 为 (batch_size, 3, 64, 64)
    print("Speed_now shape:", speed_now.shape)      # 为 (batch_size)
    print("speed_ago shape:", speed_ago.shape)          # 为 (batch_size, 16)
    break

# @title resnet_cbam

__all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
           'resnet152_cbam']

model_urls = {'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'}

def conv3x3(in_planes, out_planes, stride=1):
    "3x3 convolution with padding"
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)

class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)

        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                                nn.ReLU(),
                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)

class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)

        self.ca = ChannelAttention(planes)
        self.sa = SpatialAttention()

        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)

        return out

class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(planes * 4)
        self.relu = nn.ReLU(inplace=True)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)

        return out


class ResNet(nn.Module):

    def __init__(self, block, layers, num_classes=64):
        self.inplanes = 64
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)   # (batch_size, 2048)
        x = self.fc(x)  # (batch_size, 1000)
        return x


def resnet50_cbam(pretrained=False, **kwargs):
    """Constructs a ResNet-50 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
    if pretrained:
        pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
        now_state_dict = model.state_dict()
        now_state_dict.update(pretrained_state_dict)
        model.load_state_dict(now_state_dict)
    return model



# @title 整体网络搭建
# LSTM和CNN网络模型
seq_length = 8
input_size = 3          # 单个时间步的输入转角、速度、加速度
hidden_size = 15        # LSTM 的隐藏状态维度
num_layers = 1          # LSTM 层数
fusion_size = 64        # 融合的图像特征向量大小
output_size = 1         # 最终输出（预测的转向角）
class LSTMPredictor(nn.Module):
    def __init__(self, input_size=3, hidden_size=15, num_layers=1):
        super(LSTMPredictor, self).__init__()
        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size * seq_length, fusion_size)
    def forward(self, x):
        # 输入 x 的形状: (batch_size, seq_len, input_size)
        lstm_out, (hn, cn) = self.lstm(x) # lstm_out:(batch_size, seq_length, hidden_size) hn|cn:(num_layers, batch_size, hidden_size)
        lstm_out = lstm_out.reshape(x.size(0), -1) #  (batch_size, seq_length * hidden_size)
        return self.fc(lstm_out) # 输出:[batch, hidden_size*seq_length]->[batch_size, fusion_size]

# R+C + LSTM 融合模型
class CNN_LSTM_Fusion(nn.Module):
    def __init__(self, input_size, res_cbam, hidden_size=15, fusion_size=64, output_size=1):
        super(CNN_LSTM_Fusion, self).__init__()
        self.res_cbam = res_cbam  # 预定义的图像类型网络（这里选择了Resnet+CBAM）
        self.hidden_size = hidden_size
        self.fusion_size = fusion_size
        self.control_net = nn.Sequential(
            nn.Linear(48, 96),
            nn.ReLU(),
            nn.Linear(96, 128),
            nn.ReLU(),
            nn.Linear(128, 24))

        self.lstm = LSTMPredictor(input_size=input_size, hidden_size=hidden_size)    # LSTM 网络
        # 全连接层，用于融合 CNN 和 LSTM 的特征
        self.fc_fusion = nn.Sequential(
            nn.Linear(fusion_size + fusion_size, 64),
            nn.ReLU(),
            nn.Linear(64, output_size))
    def forward(self, speed_ago, yaw_ago, accel_ago, img_inputs):
        """
        :img_inputs为(batch_size, 3, 64, 64)
        :speed_now.shape为(batch_size)
        :speed_ago.shape为(batch_size, 16)
        :param lstm_inputs: LSTM 的输入 (batch_size, seq_len, input_size)
        :param cnn_inputs: CNN 的输入 (batch_size, 3, 64, 64)
        """
        batch_size, c, h, w = img_inputs.shape
        # 提取图像特征，形状为 (batch_size, fusion_size)
        cnn_features = self.res_cbam(img_inputs) # CNN 输出形状为(batch_size, fusion_size)
        print(cnn_features.shape)

        # 从 LSTM 获取时间序列特征

        control_ago = torch.cat([speed_ago, yaw_ago, accel_ago], dim=1)
        control_connect = self.control_net(control_ago)
        control_connect = control_connect.reshape(control_connect.size(0), 8, 3)
        lstm_out = self.lstm(control_connect) # [batch_size, fusion_size]

        # 获取图像的特征(batch_size, 64)
        img_last = cnn_features
        # 融合特征
        fusion_features = torch.cat([lstm_out, img_last], dim=1)  # (batch_size, hidden_size + fusion_size)
        print(fusion_features.shape)
        # 通过全连接层输出
        output = self.fc_fusion(fusion_features)  # (batch_size, output_size)
        return output

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard
# %tensorboard --logdir=./logs --port=6006

# @title 定义loss函数、预测头

import torch
import torch.nn.functional as F

class SomeModel(torch.nn.Module):
    def __init__(self, temporal_decay, use_huber, delta, accel_weight, steer_weight):
        super(SomeModel, self).__init__()
        self.temporal_decay = temporal_decay  # 时序衰减因子，控制近期帧权重衰减程度
        self.use_huber = use_huber  # 是否使用 Huber Loss 的标志
        self.delta = delta  # Huber Loss 中的 delta 参数
        self.accel_weight = accel_weight  # 加速度损失的权重系数
        self.steer_weight = steer_weight  # 转角损失的权重系数
        # 假设 angle_diff 是模型类中定义好的计算角度差的方法，这里补充示例实现（如果实际有更复杂逻辑需替换）
    def angle_diff(self, pred, true):
        return true - pred

    def forward(self, y_pred, accel_pred, accel_true, steer_pred, steer_true, seq_len):
        # 计算时序权重（近期帧权重高）
        # 生成 0 到 seq_len - 1 的序列，计算衰减后的权重
        time_weights = torch.pow(self.temporal_decay,
                      torch.arange(seq_len, dtype=torch.float32, device=y_pred.device))
        # 扩展维度，变成 [1, seq_len, 1] 形状，方便后续与损失张量广播相乘
        time_weights = time_weights.unsqueeze(0).unsqueeze(-1)

        # 加速度损失计算
        if self.use_huber:
            # 使用 Huber Loss，reduction='none' 保留每个元素的损失值，不做降维
            accel_loss = F.huber_loss(accel_pred, accel_true, delta=self.delta, reduction='none')
        else:
            # 使用 MSE Loss，同样保留每个元素损失值
            accel_loss = F.mse_loss(accel_pred, accel_true, reduction='none')

        # 转角损失计算（使用角度差）
        angle_errors = self.angle_diff(steer_pred, steer_true)
        if self.use_huber:
            # 与 0 比较计算 Huber Loss，衡量角度误差
            steer_loss = F.huber_loss(angle_errors,
                                      torch.zeros_like(angle_errors),
                                      delta=self.delta,
                                      reduction='none')
        else:
            # 直接计算角度误差的平方作为损失（类似 MSE 思路）
            steer_loss = torch.square(angle_errors)

        # 应用时序权重，对每个时刻的损失按权重加权后求平均
        accel_loss = (accel_loss * time_weights).mean()
        steer_loss = (steer_loss * time_weights).mean()

        # 加权总损失，将加速度损失和转角损失按各自权重相加
        total_loss = self.accel_weight * accel_loss + self.steer_weight * steer_loss
        return total_loss

# @title 开始训练

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

resnet_cbam = resnet50_cbam()
resnet_cbam.to(device)

fusion_model = CNN_LSTM_Fusion(input_size, resnet_cbam, hidden_size, fusion_size=64, output_size=1) # 这里使用了resnet50_cbam
fusion_model.to(device)

loss_fun = nn.MSELoss()  # 回归任务使用均方误差损失
optimizer = optim.Adam(fusion_model.parameters(), lr=0.001)
Loss = 10

# 创建日志保存目录（如不存在则自动创建）
log_dir = "./logs"  # 日志文件保存路径
os.makedirs(log_dir, exist_ok=True)

# 初始化writer，指定日志目录
writer = SummaryWriter(log_dir=log_dir)

for epoch in range(20):
    for batch_idx, data in enumerate(train_dataloader):
        img, speed_now, yaw_now, accel_now, speed_ago, yaw_ago, accel_ago = data
        if batch_idx==0:
          print("Image shape:", img.shape)        # 为 (batch_size, 3, 64, 64)
          print("Speed_now shape:", speed_now.shape)      # 为 (batch_size)
          print("speed_ago shape:", speed_ago.shape)          # 为 (batch_size, 16)
        if torch.cuda.is_available(): # 执行到这一步需要30s的时间
            img = img.cuda()
            speed_ago = speed_ago.cuda()
            yaw_ago = yaw_ago.cuda()
            accel_ago = accel_ago.cuda()
            speed_now = speed_now.cuda()
            yaw_now = yaw_now.cuda()
            accel_now = accel_now.cuda()

        outputs = fusion_model(speed_ago, yaw_ago, accel_ago, img) # (batch_size, output_size)
        speed_now = speed_now.unsqueeze(1)
        Loss = loss_fun(outputs, speed_now)
        print(outputs, "and" , speed_now)
        optimizer.zero_grad()
        Loss.backward()
        optimizer.step()
        print('LOSS:', Loss)
        global_step = epoch * len(train_dataloader) + batch_idx  # 计算全局步数
        if global_step %10 ==0:
            writer.add_scalar('Loss/train', Loss.item(), global_step)
        # writer.add_scalar('Loss/train', Loss, epoch)
writer.close()