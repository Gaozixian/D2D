============================================================
ResNet50+CBAM 语义分割训练 - 增强版
============================================================
数据路径: F:\Gaozixian\D2D
批次大小: 4
学习率: 0.0001
训练轮数: 50
模型保存目录: checkpoints
============================================================
使用设备: cuda
GPU: NVIDIA GeForce RTX 3080
GPU显存: 12.00 GB
Cityscapes train set: 2975 images
Cityscapes val set: 500 images

创建模型...
成功加载ImageNet预训练权重
总参数数量: 33,212,283
可训练参数: 33,212,283
============================================================
开始训练 ResNet50+CBAM 语义分割模型
============================================================

Epoch 1/50
----------------------------------------
  Batch 0/744, Loss: 2.3206
  Batch 50/744, Loss: 0.9623
  Batch 100/744, Loss: 0.9602
  Batch 150/744, Loss: 0.7213
  Batch 200/744, Loss: 0.7004
  Batch 250/744, Loss: 0.6683
  Batch 300/744, Loss: 0.6906
  Batch 350/744, Loss: 0.7479
  Batch 400/744, Loss: 0.6241
  Batch 450/744, Loss: 0.6796
  Batch 500/744, Loss: 0.5854
  Batch 550/744, Loss: 0.5552
  Batch 600/744, Loss: 0.5544
  Batch 650/744, Loss: 0.8026
  Batch 700/744, Loss: 0.6049
Train Loss: 0.7432
Val Loss: 0.5799, mIoU: 0.4419
保存最佳模型！mIoU: 0.4419

Epoch 2/50
----------------------------------------
  Batch 0/744, Loss: 0.5599
  Batch 50/744, Loss: 0.5071
  Batch 100/744, Loss: 0.4669
  Batch 150/744, Loss: 0.5187
  Batch 200/744, Loss: 0.6094
  Batch 250/744, Loss: 0.4664
  Batch 300/744, Loss: 0.4758
  Batch 350/744, Loss: 0.5232
  Batch 400/744, Loss: 0.5167
  Batch 450/744, Loss: 0.4667
  Batch 500/744, Loss: 0.4469
  Batch 550/744, Loss: 0.4637
  Batch 600/744, Loss: 0.4246
  Batch 650/744, Loss: 0.4437
  Batch 700/744, Loss: 0.4468
Train Loss: 0.5042
Val Loss: 0.4720, mIoU: 0.4578
保存最佳模型！mIoU: 0.4578

Epoch 3/50
----------------------------------------
  Batch 0/744, Loss: 0.4917
  Batch 50/744, Loss: 0.4410
  Batch 100/744, Loss: 0.4267
  Batch 150/744, Loss: 0.4698
  Batch 200/744, Loss: 0.4925
  Batch 250/744, Loss: 0.4258
  Batch 300/744, Loss: 0.5289
  Batch 350/744, Loss: 0.3585
  Batch 400/744, Loss: 0.4744
  Batch 450/744, Loss: 0.4086
  Batch 500/744, Loss: 0.3815
  Batch 550/744, Loss: 0.4104
  Batch 600/744, Loss: 0.4099
  Batch 650/744, Loss: 0.4087
  Batch 700/744, Loss: 0.4694
Train Loss: 0.4395
Val Loss: 0.4470, mIoU: 0.5011
保存最佳模型！mIoU: 0.5011

Epoch 4/50
----------------------------------------
  Batch 0/744, Loss: 0.4019
  Batch 50/744, Loss: 0.4520
  Batch 100/744, Loss: 0.3829
  Batch 150/744, Loss: 0.4200
  Batch 200/744, Loss: 0.4197
  Batch 250/744, Loss: 0.4502
  Batch 300/744, Loss: 0.4172
  Batch 350/744, Loss: 0.3417
  Batch 400/744, Loss: 0.3854
  Batch 450/744, Loss: 0.3556
  Batch 500/744, Loss: 0.3930
  Batch 550/744, Loss: 0.4531
  Batch 600/744, Loss: 0.4013
  Batch 650/744, Loss: 0.3975
  Batch 700/744, Loss: 0.3440
Train Loss: 0.4024
Val Loss: 0.4007, mIoU: 0.5623
保存最佳模型！mIoU: 0.5623

Epoch 5/50
----------------------------------------
  Batch 0/744, Loss: 0.3670
  Batch 50/744, Loss: 0.3470
  Batch 100/744, Loss: 0.4129
  Batch 150/744, Loss: 0.4523
  Batch 200/744, Loss: 0.3784
  Batch 250/744, Loss: 0.3268
  Batch 300/744, Loss: 0.3317
  Batch 350/744, Loss: 0.2853
  Batch 400/744, Loss: 0.3402
  Batch 450/744, Loss: 0.3745
  Batch 500/744, Loss: 0.4224
  Batch 550/744, Loss: 0.3783
  Batch 600/744, Loss: 0.4117
  Batch 650/744, Loss: 0.3669
  Batch 700/744, Loss: 0.3689
Train Loss: 0.3778
Val Loss: 0.4148, mIoU: 0.5397
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 6/50
----------------------------------------
  Batch 0/744, Loss: 0.3384
  Batch 50/744, Loss: 0.3896
  Batch 100/744, Loss: 0.3498
  Batch 150/744, Loss: 0.3685
  Batch 200/744, Loss: 0.3638
  Batch 250/744, Loss: 0.3490
  Batch 300/744, Loss: 0.4091
  Batch 350/744, Loss: 0.3491
  Batch 400/744, Loss: 0.3639
  Batch 450/744, Loss: 0.3242
  Batch 500/744, Loss: 0.3240
  Batch 550/744, Loss: 0.3382
  Batch 600/744, Loss: 0.3433
  Batch 650/744, Loss: 0.3843
  Batch 700/744, Loss: 0.4081
Train Loss: 0.3615
Val Loss: 0.3804, mIoU: 0.5768
保存最佳模型！mIoU: 0.5768

Epoch 7/50
----------------------------------------
  Batch 0/744, Loss: 0.3459
  Batch 50/744, Loss: 0.3605
  Batch 100/744, Loss: 0.3790
  Batch 150/744, Loss: 0.2838
  Batch 200/744, Loss: 0.3706
  Batch 250/744, Loss: 0.3808
  Batch 300/744, Loss: 0.3457
  Batch 350/744, Loss: 0.3529
  Batch 400/744, Loss: 0.3641
  Batch 450/744, Loss: 0.3456
  Batch 500/744, Loss: 0.3260
  Batch 550/744, Loss: 0.3063
  Batch 600/744, Loss: 0.3630
  Batch 650/744, Loss: 0.3114
  Batch 700/744, Loss: 0.3220
Train Loss: 0.3512
Val Loss: 0.3728, mIoU: 0.6028
保存最佳模型！mIoU: 0.6028

Epoch 8/50
----------------------------------------
  Batch 0/744, Loss: 0.3675
  Batch 50/744, Loss: 0.3593
  Batch 100/744, Loss: 0.3627
  Batch 150/744, Loss: 0.3975
  Batch 200/744, Loss: 0.3265
  Batch 250/744, Loss: 0.3758
  Batch 300/744, Loss: 0.3956
  Batch 350/744, Loss: 0.3026
  Batch 400/744, Loss: 0.3250
  Batch 450/744, Loss: 0.3140
  Batch 500/744, Loss: 0.4012
  Batch 550/744, Loss: 0.2989
  Batch 600/744, Loss: 0.3219
  Batch 650/744, Loss: 0.3060
  Batch 700/744, Loss: 0.3504
Train Loss: 0.3405
Val Loss: 0.3771, mIoU: 0.5892

Epoch 9/50
----------------------------------------
  Batch 0/744, Loss: 0.3497
  Batch 50/744, Loss: 0.3949
  Batch 100/744, Loss: 0.3332
  Batch 150/744, Loss: 0.3243
  Batch 200/744, Loss: 0.3110
  Batch 250/744, Loss: 0.3632
  Batch 300/744, Loss: 0.2815
  Batch 350/744, Loss: 0.3731
  Batch 400/744, Loss: 0.3085
  Batch 450/744, Loss: 0.3001
  Batch 500/744, Loss: 0.3048
  Batch 550/744, Loss: 0.7754
  Batch 600/744, Loss: 0.3372
  Batch 650/744, Loss: 0.3404
  Batch 700/744, Loss: 0.3344
Train Loss: 0.3287
Val Loss: 0.3604, mIoU: 0.6110
保存最佳模型！mIoU: 0.6110

Epoch 10/50
----------------------------------------
  Batch 0/744, Loss: 0.3446
  Batch 50/744, Loss: 0.3446
  Batch 100/744, Loss: 0.2970
  Batch 150/744, Loss: 0.3298
  Batch 200/744, Loss: 0.3100
  Batch 250/744, Loss: 0.3222
  Batch 300/744, Loss: 0.3563
  Batch 350/744, Loss: 0.2681
  Batch 400/744, Loss: 0.2948
  Batch 450/744, Loss: 0.3196
  Batch 500/744, Loss: 0.2754
  Batch 550/744, Loss: 0.3230
  Batch 600/744, Loss: 0.3148
  Batch 650/744, Loss: 0.3997
  Batch 700/744, Loss: 0.3214
Train Loss: 0.3252
Val Loss: 0.3603, mIoU: 0.6041
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 11/50
----------------------------------------
  Batch 0/744, Loss: 0.3808
  Batch 50/744, Loss: 0.2355
  Batch 100/744, Loss: 0.3355
  Batch 150/744, Loss: 0.2994
  Batch 200/744, Loss: 0.3295
  Batch 250/744, Loss: 0.2376
  Batch 300/744, Loss: 0.4163
  Batch 350/744, Loss: 0.3327
  Batch 400/744, Loss: 0.3166
  Batch 450/744, Loss: 0.3563
  Batch 500/744, Loss: 0.2832
  Batch 550/744, Loss: 0.3086
  Batch 600/744, Loss: 0.2814
  Batch 650/744, Loss: 0.2810
  Batch 700/744, Loss: 0.2817
Train Loss: 0.3160
Val Loss: 0.3592, mIoU: 0.6226
保存最佳模型！mIoU: 0.6226

Epoch 12/50
----------------------------------------
  Batch 0/744, Loss: 0.2913
  Batch 50/744, Loss: 0.3361
  Batch 100/744, Loss: 0.3013
  Batch 150/744, Loss: 0.3019
  Batch 200/744, Loss: 0.2710
  Batch 250/744, Loss: 0.3055
  Batch 300/744, Loss: 0.2827
  Batch 350/744, Loss: 0.2070
  Batch 400/744, Loss: 0.4180
  Batch 450/744, Loss: 0.2725
  Batch 500/744, Loss: 0.2798
  Batch 550/744, Loss: 0.3803
  Batch 600/744, Loss: 0.3323
  Batch 650/744, Loss: 0.3335
  Batch 700/744, Loss: 0.2764
Train Loss: 0.3104
Val Loss: 0.3526, mIoU: 0.6133

Epoch 13/50
----------------------------------------
  Batch 0/744, Loss: 0.2866
  Batch 50/744, Loss: 0.3049
  Batch 100/744, Loss: 0.2747
  Batch 150/744, Loss: 0.3079
  Batch 200/744, Loss: 0.2038
  Batch 250/744, Loss: 0.3504
  Batch 300/744, Loss: 0.3004
  Batch 350/744, Loss: 0.3206
  Batch 400/744, Loss: 0.2937
  Batch 450/744, Loss: 0.2463
  Batch 500/744, Loss: 0.3447
  Batch 550/744, Loss: 0.2674
  Batch 600/744, Loss: 0.2910
  Batch 650/744, Loss: 0.3336
  Batch 700/744, Loss: 0.2868
Train Loss: 0.3055
Val Loss: 0.3450, mIoU: 0.6425
保存最佳模型！mIoU: 0.6425

Epoch 14/50
----------------------------------------
  Batch 0/744, Loss: 0.2386
  Batch 50/744, Loss: 0.2997
  Batch 100/744, Loss: 0.3187
  Batch 150/744, Loss: 0.2784
  Batch 200/744, Loss: 0.3174
  Batch 250/744, Loss: 0.3089
  Batch 300/744, Loss: 0.2840
  Batch 350/744, Loss: 0.4742
  Batch 400/744, Loss: 0.3326
  Batch 450/744, Loss: 0.2930
  Batch 500/744, Loss: 0.3061
  Batch 550/744, Loss: 0.3947
  Batch 600/744, Loss: 0.2866
  Batch 650/744, Loss: 0.2334
  Batch 700/744, Loss: 0.2894
Train Loss: 0.2974
Val Loss: 0.3580, mIoU: 0.6142

Epoch 15/50
----------------------------------------
  Batch 0/744, Loss: 0.2523
  Batch 50/744, Loss: 0.2474
  Batch 100/744, Loss: 0.2700
  Batch 150/744, Loss: 0.2951
  Batch 200/744, Loss: 0.3401
  Batch 250/744, Loss: 0.3245
  Batch 300/744, Loss: 0.3230
  Batch 350/744, Loss: 0.3178
  Batch 400/744, Loss: 0.2758
  Batch 450/744, Loss: 0.2711
  Batch 500/744, Loss: 0.2980
  Batch 550/744, Loss: 0.3028
  Batch 600/744, Loss: 0.3235
  Batch 650/744, Loss: 0.2333
  Batch 700/744, Loss: 0.2459
Train Loss: 0.2924
Val Loss: 0.3534, mIoU: 0.6034
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 16/50
----------------------------------------
  Batch 0/744, Loss: 0.2996
  Batch 50/744, Loss: 0.2622
  Batch 100/744, Loss: 0.2995
  Batch 150/744, Loss: 0.2957
  Batch 200/744, Loss: 0.3158
  Batch 250/744, Loss: 0.2427
  Batch 300/744, Loss: 0.2993
  Batch 350/744, Loss: 0.2872
  Batch 400/744, Loss: 0.2672
  Batch 450/744, Loss: 0.2224
  Batch 500/744, Loss: 0.3071
  Batch 550/744, Loss: 0.2434
  Batch 600/744, Loss: 0.2961
  Batch 650/744, Loss: 0.2459
  Batch 700/744, Loss: 0.2965
Train Loss: 0.2820
Val Loss: 0.3286, mIoU: 0.6454
保存最佳模型！mIoU: 0.6454

Epoch 17/50
----------------------------------------
  Batch 0/744, Loss: 0.2144
  Batch 50/744, Loss: 0.2449
  Batch 100/744, Loss: 0.2874
  Batch 150/744, Loss: 0.2650
  Batch 200/744, Loss: 0.2662
  Batch 250/744, Loss: 0.3230
  Batch 300/744, Loss: 0.2577
  Batch 350/744, Loss: 0.2488
  Batch 400/744, Loss: 0.3114
  Batch 450/744, Loss: 0.2989
  Batch 500/744, Loss: 0.3106
  Batch 550/744, Loss: 0.2881
  Batch 600/744, Loss: 0.2358
  Batch 650/744, Loss: 0.2469
  Batch 700/744, Loss: 0.3460
Train Loss: 0.2803
Val Loss: 0.3376, mIoU: 0.6209

Epoch 18/50
----------------------------------------
  Batch 0/744, Loss: 0.3274
  Batch 50/744, Loss: 0.2623
  Batch 100/744, Loss: 0.2666
  Batch 150/744, Loss: 0.2996
  Batch 200/744, Loss: 0.2948
  Batch 250/744, Loss: 0.2530
  Batch 300/744, Loss: 0.2867
  Batch 350/744, Loss: 0.2999
  Batch 400/744, Loss: 0.2870
  Batch 450/744, Loss: 0.2540
  Batch 500/744, Loss: 0.2613
  Batch 550/744, Loss: 0.2525
  Batch 600/744, Loss: 0.3312
  Batch 650/744, Loss: 0.2926
  Batch 700/744, Loss: 0.2457
Train Loss: 0.2733
Val Loss: 0.3300, mIoU: 0.6282

Epoch 19/50
----------------------------------------
  Batch 0/744, Loss: 0.3357
  Batch 50/744, Loss: 0.2356
  Batch 100/744, Loss: 0.2475
  Batch 150/744, Loss: 0.3059
  Batch 200/744, Loss: 0.3191
  Batch 250/744, Loss: 0.2429
  Batch 300/744, Loss: 0.2775
  Batch 350/744, Loss: 0.2404
  Batch 400/744, Loss: 0.2823
  Batch 450/744, Loss: 0.2800
  Batch 500/744, Loss: 0.2241
  Batch 550/744, Loss: 0.2756
  Batch 600/744, Loss: 0.2743
  Batch 650/744, Loss: 0.3180
  Batch 700/744, Loss: 0.2150
Train Loss: 0.2667
Val Loss: 0.3259, mIoU: 0.6414

Epoch 20/50
----------------------------------------
  Batch 0/744, Loss: 0.2308
  Batch 50/744, Loss: 0.2676
  Batch 100/744, Loss: 0.2705
  Batch 150/744, Loss: 0.2751
  Batch 200/744, Loss: 0.2558
  Batch 250/744, Loss: 0.2667
  Batch 300/744, Loss: 0.2974
  Batch 350/744, Loss: 0.1892
  Batch 400/744, Loss: 0.2103
  Batch 450/744, Loss: 0.1393
  Batch 500/744, Loss: 0.2255
  Batch 550/744, Loss: 0.2519
  Batch 600/744, Loss: 0.2704
  Batch 650/744, Loss: 0.2966
  Batch 700/744, Loss: 0.2150
Train Loss: 0.2559
Val Loss: 0.3108, mIoU: 0.6380
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 21/50
----------------------------------------
  Batch 0/744, Loss: 0.2494
  Batch 50/744, Loss: 0.2177
  Batch 100/744, Loss: 0.3075
  Batch 150/744, Loss: 0.2228
  Batch 200/744, Loss: 0.2508
  Batch 250/744, Loss: 0.2680
  Batch 300/744, Loss: 0.2932
  Batch 350/744, Loss: 0.2799
  Batch 400/744, Loss: 0.2238
  Batch 450/744, Loss: 0.3169
  Batch 500/744, Loss: 0.2161
  Batch 550/744, Loss: 0.2889
  Batch 600/744, Loss: 0.2362
  Batch 650/744, Loss: 0.2252
  Batch 700/744, Loss: 0.2306
Train Loss: 0.2332
Val Loss: 0.3163, mIoU: 0.6225

Epoch 22/50
----------------------------------------
  Batch 0/744, Loss: 0.1511
  Batch 50/744, Loss: 0.2063
  Batch 100/744, Loss: 0.1832
  Batch 150/744, Loss: 0.1858
  Batch 200/744, Loss: 0.1675
  Batch 250/744, Loss: 0.2999
  Batch 300/744, Loss: 0.1977
  Batch 350/744, Loss: 0.2252
  Batch 400/744, Loss: 0.2378
  Batch 450/744, Loss: 0.2089
  Batch 500/744, Loss: 0.2407
  Batch 550/744, Loss: 0.1666
  Batch 600/744, Loss: 0.2550
  Batch 650/744, Loss: 0.4313
  Batch 700/744, Loss: 0.2582
Train Loss: 0.2282
Val Loss: 0.3023, mIoU: 0.6434

Epoch 23/50
----------------------------------------
  Batch 0/744, Loss: 0.1662
  Batch 50/744, Loss: 0.2210
  Batch 100/744, Loss: 0.2250
  Batch 150/744, Loss: 0.1667
  Batch 200/744, Loss: 0.1530
  Batch 250/744, Loss: 0.1920
  Batch 300/744, Loss: 0.1390
  Batch 350/744, Loss: 0.2754
  Batch 400/744, Loss: 0.2224
  Batch 450/744, Loss: 0.1958
  Batch 500/744, Loss: 0.1744
  Batch 550/744, Loss: 0.2429
  Batch 600/744, Loss: 0.2340
  Batch 650/744, Loss: 0.1816
  Batch 700/744, Loss: 0.2646
Train Loss: 0.2157
Val Loss: 0.2885, mIoU: 0.6514
保存最佳模型！mIoU: 0.6514

Epoch 24/50
----------------------------------------
  Batch 0/744, Loss: 0.2077
  Batch 50/744, Loss: 0.2304
  Batch 100/744, Loss: 0.2188
  Batch 150/744, Loss: 0.1578
  Batch 200/744, Loss: 0.1975
  Batch 250/744, Loss: 0.1883
  Batch 300/744, Loss: 0.2866
  Batch 350/744, Loss: 0.2262
  Batch 400/744, Loss: 0.2204
  Batch 450/744, Loss: 0.2581
  Batch 500/744, Loss: 0.2308
  Batch 550/744, Loss: 0.2037
  Batch 600/744, Loss: 0.3103
  Batch 650/744, Loss: 0.2182
  Batch 700/744, Loss: 0.5701
Train Loss: 0.2130
Val Loss: 0.2959, mIoU: 0.6516
保存最佳模型！mIoU: 0.6516

Epoch 25/50
----------------------------------------
  Batch 0/744, Loss: 0.1612
  Batch 50/744, Loss: 0.2033
  Batch 100/744, Loss: 0.2364
  Batch 150/744, Loss: 0.1919
  Batch 200/744, Loss: 0.2119
  Batch 250/744, Loss: 0.2197
  Batch 300/744, Loss: 0.2182
  Batch 350/744, Loss: 0.2977
  Batch 400/744, Loss: 0.2501
  Batch 450/744, Loss: 0.2154
  Batch 500/744, Loss: 0.1958
  Batch 550/744, Loss: 0.1628
  Batch 600/744, Loss: 0.2213
  Batch 650/744, Loss: 0.1467
  Batch 700/744, Loss: 0.3204
Train Loss: 0.2134
Val Loss: 0.2830, mIoU: 0.6748
保存最佳模型！mIoU: 0.6748
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 26/50
----------------------------------------
  Batch 0/744, Loss: 0.1889
  Batch 50/744, Loss: 0.2052
  Batch 100/744, Loss: 0.2168
  Batch 150/744, Loss: 0.1354
  Batch 200/744, Loss: 0.2447
  Batch 250/744, Loss: 0.2119
  Batch 300/744, Loss: 0.1611
  Batch 350/744, Loss: 0.1716
  Batch 400/744, Loss: 0.1422
  Batch 450/744, Loss: 0.1984
  Batch 500/744, Loss: 0.2026
  Batch 550/744, Loss: 0.2234
  Batch 600/744, Loss: 0.1997
  Batch 650/744, Loss: 0.2278
  Batch 700/744, Loss: 0.2467
Train Loss: 0.2021
Val Loss: 0.2980, mIoU: 0.6447

Epoch 27/50
----------------------------------------
  Batch 0/744, Loss: 0.1636
  Batch 50/744, Loss: 0.1741
  Batch 100/744, Loss: 0.2001
  Batch 150/744, Loss: 0.1812
  Batch 200/744, Loss: 0.1969
  Batch 250/744, Loss: 0.1306
  Batch 300/744, Loss: 0.1359
  Batch 350/744, Loss: 0.1896
  Batch 400/744, Loss: 0.1304
  Batch 450/744, Loss: 0.1591
  Batch 500/744, Loss: 0.1418
  Batch 550/744, Loss: 0.2114
  Batch 600/744, Loss: 0.1090
  Batch 650/744, Loss: 0.1741
  Batch 700/744, Loss: 0.2470
Train Loss: 0.2048
Val Loss: 0.2909, mIoU: 0.6366

Epoch 28/50
----------------------------------------
  Batch 0/744, Loss: 0.1375
  Batch 50/744, Loss: 0.2097
  Batch 100/744, Loss: 0.1929
  Batch 150/744, Loss: 0.1433
  Batch 200/744, Loss: 0.1800
  Batch 250/744, Loss: 0.1492
  Batch 300/744, Loss: 0.1790
  Batch 350/744, Loss: 0.1630
  Batch 400/744, Loss: 0.2339
  Batch 450/744, Loss: 0.1775
  Batch 500/744, Loss: 0.2039
  Batch 550/744, Loss: 0.1862
  Batch 600/744, Loss: 0.1798
  Batch 650/744, Loss: 0.1960
  Batch 700/744, Loss: 0.2503
Train Loss: 0.2020
Val Loss: 0.2751, mIoU: 0.6738

Epoch 29/50
----------------------------------------
  Batch 0/744, Loss: 0.2345
  Batch 50/744, Loss: 0.2365
  Batch 100/744, Loss: 0.1505
  Batch 150/744, Loss: 0.2357
  Batch 200/744, Loss: 0.1151
  Batch 250/744, Loss: 0.1395
  Batch 300/744, Loss: 0.2024
  Batch 350/744, Loss: 0.1476
  Batch 400/744, Loss: 0.2116
  Batch 450/744, Loss: 0.1780
  Batch 500/744, Loss: 0.1838
  Batch 550/744, Loss: 0.2356
  Batch 600/744, Loss: 0.2202
  Batch 650/744, Loss: 0.1716
  Batch 700/744, Loss: 0.1999
Train Loss: 0.1975
Val Loss: 0.2768, mIoU: 0.6722

Epoch 30/50
----------------------------------------
  Batch 0/744, Loss: 0.2545
  Batch 50/744, Loss: 0.1666
  Batch 100/744, Loss: 0.2014
  Batch 150/744, Loss: 0.1829
  Batch 200/744, Loss: 0.1225
  Batch 250/744, Loss: 0.1806
  Batch 300/744, Loss: 0.1535
  Batch 350/744, Loss: 0.2052
  Batch 400/744, Loss: 0.2273
  Batch 450/744, Loss: 0.1487
  Batch 500/744, Loss: 0.1783
  Batch 550/744, Loss: 0.1749
  Batch 600/744, Loss: 0.2248
  Batch 650/744, Loss: 0.2076
  Batch 700/744, Loss: 0.1893
Train Loss: 0.1915
Val Loss: 0.2813, mIoU: 0.6549
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 31/50
----------------------------------------
  Batch 0/744, Loss: 0.1884
  Batch 50/744, Loss: 0.1501
  Batch 100/744, Loss: 0.2807
  Batch 150/744, Loss: 0.2046
  Batch 200/744, Loss: 0.1864
  Batch 250/744, Loss: 0.1418
  Batch 300/744, Loss: 0.2481
  Batch 350/744, Loss: 0.1858
  Batch 400/744, Loss: 0.1820
  Batch 450/744, Loss: 0.1897
  Batch 500/744, Loss: 0.2188
  Batch 550/744, Loss: 0.1878
  Batch 600/744, Loss: 0.1765
  Batch 650/744, Loss: 0.1754
  Batch 700/744, Loss: 0.1918
Train Loss: 0.1931
Val Loss: 0.2983, mIoU: 0.6584

Epoch 32/50
----------------------------------------
  Batch 0/744, Loss: 0.1857
  Batch 50/744, Loss: 0.1461
  Batch 100/744, Loss: 0.2144
  Batch 150/744, Loss: 0.1299
  Batch 200/744, Loss: 0.1809
  Batch 250/744, Loss: 0.1567
  Batch 300/744, Loss: 0.1130
  Batch 350/744, Loss: 0.2283
  Batch 400/744, Loss: 0.2100
  Batch 450/744, Loss: 0.2433
  Batch 500/744, Loss: 0.1934
  Batch 550/744, Loss: 0.2214
  Batch 600/744, Loss: 0.2016
  Batch 650/744, Loss: 0.1987
  Batch 700/744, Loss: 0.2821
Train Loss: 0.1879
Val Loss: 0.2792, mIoU: 0.6705

Epoch 33/50
----------------------------------------
  Batch 0/744, Loss: 0.1803
  Batch 50/744, Loss: 0.1625
  Batch 100/744, Loss: 0.1767
  Batch 150/744, Loss: 0.2427
  Batch 200/744, Loss: 0.2022
  Batch 250/744, Loss: 0.1545
  Batch 300/744, Loss: 0.1420
  Batch 350/744, Loss: 0.2008
  Batch 400/744, Loss: 0.1429
  Batch 450/744, Loss: 0.1532
  Batch 500/744, Loss: 0.1678
  Batch 550/744, Loss: 0.1894
  Batch 600/744, Loss: 0.2218
  Batch 650/744, Loss: 0.1682
  Batch 700/744, Loss: 0.1958
Train Loss: 0.1863
Val Loss: 0.2799, mIoU: 0.6669

Epoch 34/50
----------------------------------------
  Batch 0/744, Loss: 0.1986
  Batch 50/744, Loss: 0.2452
  Batch 100/744, Loss: 0.2227
  Batch 150/744, Loss: 0.2128
  Batch 200/744, Loss: 0.1900
  Batch 250/744, Loss: 0.2220
  Batch 300/744, Loss: 0.1336
  Batch 350/744, Loss: 0.1684
  Batch 400/744, Loss: 0.2419
  Batch 450/744, Loss: 0.1793
  Batch 500/744, Loss: 0.1718
  Batch 550/744, Loss: 0.1714
  Batch 600/744, Loss: 0.2113
  Batch 650/744, Loss: 0.1818
  Batch 700/744, Loss: 0.1898
Train Loss: 0.1837
Val Loss: 0.2732, mIoU: 0.6684

Epoch 35/50
----------------------------------------
  Batch 0/744, Loss: 0.1577
  Batch 50/744, Loss: 0.1637
  Batch 100/744, Loss: 0.1688
  Batch 150/744, Loss: 0.1433
  Batch 200/744, Loss: 0.1926
  Batch 250/744, Loss: 0.2164
  Batch 300/744, Loss: 0.1647
  Batch 350/744, Loss: 0.1733
  Batch 400/744, Loss: 0.1540
  Batch 450/744, Loss: 0.2058
  Batch 500/744, Loss: 0.2382
  Batch 550/744, Loss: 0.1907
  Batch 600/744, Loss: 0.1561
  Batch 650/744, Loss: 0.1949
  Batch 700/744, Loss: 0.2280
Train Loss: 0.1832
Val Loss: 0.2818, mIoU: 0.6606
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 36/50
----------------------------------------
  Batch 0/744, Loss: 0.1346
  Batch 50/744, Loss: 0.1826
  Batch 100/744, Loss: 0.1679
  Batch 150/744, Loss: 0.2171
  Batch 200/744, Loss: 0.1687
  Batch 250/744, Loss: 0.2452
  Batch 300/744, Loss: 0.1766
  Batch 350/744, Loss: 0.1862
  Batch 400/744, Loss: 0.1691
  Batch 450/744, Loss: 0.1486
  Batch 500/744, Loss: 0.1961
  Batch 550/744, Loss: 0.1731
  Batch 600/744, Loss: 0.1980
  Batch 650/744, Loss: 0.1311
  Batch 700/744, Loss: 0.1731
Train Loss: 0.1812
Val Loss: 0.2722, mIoU: 0.6822
保存最佳模型！mIoU: 0.6822

Epoch 37/50
----------------------------------------
  Batch 0/744, Loss: 0.1912
  Batch 50/744, Loss: 0.1441
  Batch 100/744, Loss: 0.1662
  Batch 150/744, Loss: 0.2270
  Batch 200/744, Loss: 0.1788
  Batch 250/744, Loss: 0.1832
  Batch 300/744, Loss: 0.1544
  Batch 350/744, Loss: 0.1551
  Batch 400/744, Loss: 0.0952
  Batch 450/744, Loss: 0.1638
  Batch 500/744, Loss: 0.1745
  Batch 550/744, Loss: 0.2074
  Batch 600/744, Loss: 0.2369
  Batch 650/744, Loss: 0.2193
  Batch 700/744, Loss: 0.1431
Train Loss: 0.1791
Val Loss: 0.2643, mIoU: 0.6883
保存最佳模型！mIoU: 0.6883

Epoch 38/50
----------------------------------------
  Batch 0/744, Loss: 0.1757
  Batch 50/744, Loss: 0.2162
  Batch 100/744, Loss: 0.1695
  Batch 150/744, Loss: 0.1912
  Batch 200/744, Loss: 0.1589
  Batch 250/744, Loss: 0.2249
  Batch 300/744, Loss: 0.1651
  Batch 350/744, Loss: 0.1528
  Batch 400/744, Loss: 0.1660
  Batch 450/744, Loss: 0.2254
  Batch 500/744, Loss: 0.1974
  Batch 550/744, Loss: 0.1542
  Batch 600/744, Loss: 0.1737
  Batch 650/744, Loss: 0.1794
  Batch 700/744, Loss: 0.1338
Train Loss: 0.1757
Val Loss: 0.2751, mIoU: 0.6619

Epoch 39/50
----------------------------------------
  Batch 0/744, Loss: 0.1503
  Batch 50/744, Loss: 0.1605
  Batch 100/744, Loss: 0.1514
  Batch 150/744, Loss: 0.2017
  Batch 200/744, Loss: 0.2015
  Batch 250/744, Loss: 0.1936
  Batch 300/744, Loss: 0.1767
  Batch 350/744, Loss: 0.1354
  Batch 400/744, Loss: 0.1485
  Batch 450/744, Loss: 0.1882
  Batch 500/744, Loss: 0.1842
  Batch 550/744, Loss: 0.1432
  Batch 600/744, Loss: 0.1368
  Batch 650/744, Loss: 0.1996
  Batch 700/744, Loss: 0.2064
Train Loss: 0.1761
Val Loss: 0.2658, mIoU: 0.6969
保存最佳模型！mIoU: 0.6969

Epoch 40/50
----------------------------------------
  Batch 0/744, Loss: 0.2193
  Batch 50/744, Loss: 0.1430
  Batch 100/744, Loss: 0.1932
  Batch 150/744, Loss: 0.0969
  Batch 200/744, Loss: 0.1550
  Batch 250/744, Loss: 0.1517
  Batch 300/744, Loss: 0.2276
  Batch 350/744, Loss: 0.1471
  Batch 400/744, Loss: 0.1616
  Batch 450/744, Loss: 0.1794
  Batch 500/744, Loss: 0.2103
  Batch 550/744, Loss: 0.1942
  Batch 600/744, Loss: 0.1475
  Batch 650/744, Loss: 0.1429
  Batch 700/744, Loss: 0.1856
Train Loss: 0.1749
Val Loss: 0.2704, mIoU: 0.6785
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 41/50
----------------------------------------
  Batch 0/744, Loss: 0.1563
  Batch 50/744, Loss: 0.3153
  Batch 100/744, Loss: 0.1851
  Batch 150/744, Loss: 0.1548
  Batch 200/744, Loss: 0.1895
  Batch 250/744, Loss: 0.1516
  Batch 300/744, Loss: 0.1615
  Batch 350/744, Loss: 0.1308
  Batch 400/744, Loss: 0.1909
  Batch 450/744, Loss: 0.1792
  Batch 500/744, Loss: 0.1636
  Batch 550/744, Loss: 0.1628
  Batch 600/744, Loss: 0.1143
  Batch 650/744, Loss: 0.1405
  Batch 700/744, Loss: 0.0944
Train Loss: 0.1714
Val Loss: 0.2665, mIoU: 0.6874

Epoch 42/50
----------------------------------------
  Batch 0/744, Loss: 0.1974
  Batch 50/744, Loss: 0.1987
  Batch 100/744, Loss: 0.1384
  Batch 150/744, Loss: 0.1776
  Batch 200/744, Loss: 0.1372
  Batch 250/744, Loss: 0.2294
  Batch 300/744, Loss: 0.1323
  Batch 350/744, Loss: 0.2417
  Batch 400/744, Loss: 0.1258
  Batch 450/744, Loss: 0.1817
  Batch 500/744, Loss: 0.0711
  Batch 550/744, Loss: 0.1437
  Batch 600/744, Loss: 0.1953
  Batch 650/744, Loss: 0.2782
  Batch 700/744, Loss: 0.1473
Train Loss: 0.1716
Val Loss: 0.2704, mIoU: 0.6764

Epoch 43/50
----------------------------------------
  Batch 0/744, Loss: 0.2173
  Batch 50/744, Loss: 0.1231
  Batch 100/744, Loss: 0.1588
  Batch 150/744, Loss: 0.1383
  Batch 200/744, Loss: 0.1399
  Batch 250/744, Loss: 0.1662
  Batch 300/744, Loss: 0.1510
  Batch 350/744, Loss: 0.1573
  Batch 400/744, Loss: 0.1935
  Batch 450/744, Loss: 0.1121
  Batch 500/744, Loss: 0.2061
  Batch 550/744, Loss: 0.1999
  Batch 600/744, Loss: 0.1679
  Batch 650/744, Loss: 0.2399
  Batch 700/744, Loss: 0.1925
Train Loss: 0.1689
Val Loss: 0.2614, mIoU: 0.6957

Epoch 44/50
----------------------------------------
  Batch 0/744, Loss: 0.1728
  Batch 50/744, Loss: 0.1815
  Batch 100/744, Loss: 0.1386
  Batch 150/744, Loss: 0.1959
  Batch 200/744, Loss: 0.1707
  Batch 250/744, Loss: 0.1498
  Batch 300/744, Loss: 0.1431
  Batch 350/744, Loss: 0.1933
  Batch 400/744, Loss: 0.1819
  Batch 450/744, Loss: 0.1119
  Batch 500/744, Loss: 0.1529
  Batch 550/744, Loss: 0.1446
  Batch 600/744, Loss: 0.1672
  Batch 650/744, Loss: 0.1478
  Batch 700/744, Loss: 0.1502
Train Loss: 0.1677
Val Loss: 0.2642, mIoU: 0.6943

Epoch 45/50
----------------------------------------
  Batch 0/744, Loss: 0.1687
  Batch 50/744, Loss: 0.1570
  Batch 100/744, Loss: 0.1816
  Batch 150/744, Loss: 0.1637
  Batch 200/744, Loss: 0.1908
  Batch 250/744, Loss: 0.1605
  Batch 300/744, Loss: 0.1685
  Batch 350/744, Loss: 0.1540
  Batch 400/744, Loss: 0.1521
  Batch 450/744, Loss: 0.1477
  Batch 500/744, Loss: 0.1449
  Batch 550/744, Loss: 0.1729
  Batch 600/744, Loss: 0.1645
  Batch 650/744, Loss: 0.1573
  Batch 700/744, Loss: 0.1545
Train Loss: 0.1651
Val Loss: 0.2639, mIoU: 0.6907
Loss历史记录已保存至: checkpoints\loss_history.json

Epoch 46/50
----------------------------------------
  Batch 0/744, Loss: 0.1697
  Batch 50/744, Loss: 0.2162
  Batch 100/744, Loss: 0.1321
  Batch 150/744, Loss: 0.1307
  Batch 200/744, Loss: 0.1381
  Batch 250/744, Loss: 0.1715
  Batch 300/744, Loss: 0.1272
  Batch 350/744, Loss: 0.1506
  Batch 400/744, Loss: 0.1505
  Batch 450/744, Loss: 0.1648
  Batch 500/744, Loss: 0.1731
  Batch 550/744, Loss: 0.1747
  Batch 600/744, Loss: 0.1951
  Batch 650/744, Loss: 0.2360
  Batch 700/744, Loss: 0.2039
Train Loss: 0.1646
Val Loss: 0.2656, mIoU: 0.6862

Epoch 47/50
----------------------------------------
  Batch 0/744, Loss: 0.1976
  Batch 50/744, Loss: 0.1816
  Batch 100/744, Loss: 0.1684
  Batch 150/744, Loss: 0.1638
  Batch 200/744, Loss: 0.2198
  Batch 250/744, Loss: 0.1171
  Batch 300/744, Loss: 0.1837
  Batch 350/744, Loss: 0.1966
  Batch 400/744, Loss: 0.1531
  Batch 450/744, Loss: 0.1674
  Batch 500/744, Loss: 0.1361
  Batch 550/744, Loss: 0.2331
  Batch 600/744, Loss: 0.1676
  Batch 650/744, Loss: 0.1558
  Batch 700/744, Loss: 0.1394
Train Loss: 0.1626
Val Loss: 0.2629, mIoU: 0.6905

Epoch 48/50
----------------------------------------
  Batch 0/744, Loss: 0.2371
  Batch 50/744, Loss: 0.1530
  Batch 100/744, Loss: 0.1884
  Batch 150/744, Loss: 0.1681
  Batch 200/744, Loss: 0.1475
  Batch 250/744, Loss: 0.1390
  Batch 300/744, Loss: 0.1713
  Batch 350/744, Loss: 0.1478
  Batch 400/744, Loss: 0.1372
  Batch 450/744, Loss: 0.1495
  Batch 500/744, Loss: 0.1466
  Batch 550/744, Loss: 0.1421
  Batch 600/744, Loss: 0.1374
  Batch 650/744, Loss: 0.1320
  Batch 700/744, Loss: 0.1333
Train Loss: 0.1621
Val Loss: 0.2555, mIoU: 0.7079
保存最佳模型！mIoU: 0.7079

Epoch 49/50
----------------------------------------
  Batch 0/744, Loss: 0.1751
  Batch 50/744, Loss: 0.1817
  Batch 100/744, Loss: 0.1601
  Batch 150/744, Loss: 0.1429
  Batch 200/744, Loss: 0.1782
  Batch 250/744, Loss: 0.1790
  Batch 300/744, Loss: 0.1924
  Batch 350/744, Loss: 0.1187
  Batch 400/744, Loss: 0.1762
  Batch 450/744, Loss: 0.1373
  Batch 500/744, Loss: 0.2166
  Batch 550/744, Loss: 0.1753
  Batch 600/744, Loss: 0.1439
  Batch 650/744, Loss: 0.1942
  Batch 700/744, Loss: 0.1642
Train Loss: 0.1595
Val Loss: 0.2585, mIoU: 0.7020

Epoch 50/50
----------------------------------------
  Batch 0/744, Loss: 0.1331
  Batch 50/744, Loss: 0.2388
  Batch 100/744, Loss: 0.1088
  Batch 150/744, Loss: 0.1266
  Batch 200/744, Loss: 0.1662
  Batch 250/744, Loss: 0.1422
  Batch 300/744, Loss: 0.2041
  Batch 350/744, Loss: 0.1391
  Batch 400/744, Loss: 0.1302
  Batch 450/744, Loss: 0.1784
  Batch 500/744, Loss: 0.1598
  Batch 550/744, Loss: 0.2051
  Batch 600/744, Loss: 0.1588
  Batch 650/744, Loss: 0.1293
  Batch 700/744, Loss: 0.1894
Train Loss: 0.1594
Val Loss: 0.2603, mIoU: 0.6950
Loss历史记录已保存至: checkpoints\loss_history.json

============================================================
训练完成！开始保存最终结果...
============================================================
最终模型已保存至: checkpoints\final_model.pth
Loss曲线已保存至: checkpoints\loss_curve.png
Loss历史记录已保存至: checkpoints\loss_history.json

训练完成！最佳mIoU: 0.7079

最终结果:
  最佳验证mIoU: 0.7079

============================================================
训练完成，开始生成测试可视化结果...
============================================================
Cityscapes val set: 500 images

============================================================
开始生成测试可视化结果...
============================================================
样本 1: IoU=0.9684
  - 原始图像: frankfurt_000000_000294_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0001_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0001_overlay.png
样本 2: IoU=0.9760
  - 原始图像: frankfurt_000000_000576_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0002_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0002_overlay.png
样本 3: IoU=0.9719
  - 原始图像: frankfurt_000000_001016_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0003_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0003_overlay.png
样本 4: IoU=0.9584
  - 原始图像: frankfurt_000000_001236_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0004_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0004_overlay.png
样本 5: IoU=0.9730
  - 原始图像: frankfurt_000000_001751_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0005_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0005_overlay.png
样本 6: IoU=0.9713
  - 原始图像: frankfurt_000000_002196_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0006_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0006_overlay.png
样本 7: IoU=0.9404
  - 原始图像: frankfurt_000000_002963_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0007_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0007_overlay.png
样本 8: IoU=0.9613
  - 原始图像: frankfurt_000000_003025_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0008_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0008_overlay.png
样本 9: IoU=0.9392
  - 原始图像: frankfurt_000000_003357_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0009_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0009_overlay.png
样本 10: IoU=0.9355
  - 原始图像: frankfurt_000000_003920_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0010_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0010_overlay.png
样本 11: IoU=0.9452
  - 原始图像: frankfurt_000000_004617_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0011_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0011_overlay.png
样本 12: IoU=0.9319
  - 原始图像: frankfurt_000000_005543_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0012_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0012_overlay.png
样本 13: IoU=0.9547
  - 原始图像: frankfurt_000000_005898_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0013_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0013_overlay.png
样本 14: IoU=0.9408
  - 原始图像: frankfurt_000000_006589_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0014_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0014_overlay.png
样本 15: IoU=0.9402
  - 原始图像: frankfurt_000000_007365_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0015_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0015_overlay.png
样本 16: IoU=0.9034
  - 原始图像: frankfurt_000000_008206_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0016_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0016_overlay.png
样本 17: IoU=0.9326
  - 原始图像: frankfurt_000000_008451_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0017_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0017_overlay.png
样本 18: IoU=0.9453
  - 原始图像: frankfurt_000000_009291_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0018_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0018_overlay.png
样本 19: IoU=0.9372
  - 原始图像: frankfurt_000000_009561_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0019_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0019_overlay.png
样本 20: IoU=0.9643
  - 原始图像: frankfurt_000000_009688_leftImg8bit.png
  - 分割掩码: test_results\segmentation_masks\sample_0020_mask.png
  - 叠加图像(25%透明度): test_results\overlayed_results\sample_0020_overlay.png

测试报告已保存至: test_results\test_report.json
平均IoU: 0.9495

测试完成！共生成 20 个可视化样本
分割掩码保存在: test_results\segmentation_masks
叠加结果保存在: test_results\overlayed_results

============================================================
所有任务完成！
============================================================
最佳模型: checkpoints\best_model.pth
最终模型: checkpoints\final_model.pth
Loss历史: checkpoints\loss_history.json
Loss曲线: checkpoints\loss_curve.png
测试结果: test_results/overlayed_results/
