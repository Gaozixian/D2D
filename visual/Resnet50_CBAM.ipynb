{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CBAM模块代码 Resnet50核心模块\n",
    "两种集成策略适用于不同的应用场景。模式一适合需要精细特征增强的任务，例如小样本数据集、细粒度分类、医学图像分析等场景，因为注意力机制能够更深入地参与到每个残差块的学习过程中。模式二适合计算资源有限或大规模数据集的场景，例如ImageNet预训练、目标检测和语义分割的主干网络等，它在保持注意力机制效果的同时显著降低了模型复杂度和计算开销。"
   ],
   "id": "43e49f92b39c5b16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:48:36.744094200Z",
     "start_time": "2025-12-24T07:48:35.134601400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "ResNet50+CBAM 语义分割网络\n",
    "Windows环境兼容版本 - 增强版（包含Loss保存、模型保存、可视化）\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ],
   "id": "6ce5dea3c1e35c33",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:48:36.778592100Z",
     "start_time": "2025-12-24T07:48:36.746044500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==================== CBAM模块定义 ====================\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"通道注意力模块\"\"\"\n",
    "\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"空间注意力模块\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"完整的CBAM注意力模块（通道+空间）\"\"\"\n",
    "\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ca(x) * x\n",
    "        out = self.sa(out) * out\n",
    "        return out"
   ],
   "id": "2e5fb02cab24b37f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:48:36.846562800Z",
     "start_time": "2025-12-24T07:48:36.789799700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet50的瓶颈块\"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# ==================== 语义分割网络 ====================\n",
    "\n",
    "class ResNet50CBAM_Segmentation(nn.Module):\n",
    "    \"\"\"基于ResNet50+CBAM的语义分割网络\"\"\"\n",
    "\n",
    "    def __init__(self, block=Bottleneck, layers=[3, 4, 6, 3], num_classes=19, pretrained=False):\n",
    "        super(ResNet50CBAM_Segmentation, self).__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet编码器层\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.cbam1 = CBAM(64 * block.expansion)\n",
    "\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.cbam2 = CBAM(128 * block.expansion)\n",
    "\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.cbam3 = CBAM(256 * block.expansion)\n",
    "\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.cbam4 = CBAM(512 * block.expansion)\n",
    "\n",
    "        # 解码器部分（U-Net风格）\n",
    "        self.decoder4 = self._make_decoder_block(2048 + 1024, 256)\n",
    "        self.decoder3 = self._make_decoder_block(256 + 512, 128)\n",
    "        self.decoder2 = self._make_decoder_block(128 + 256, 64)\n",
    "        self.decoder1 = self._make_decoder_block(64 + 64, 32)\n",
    "\n",
    "        # 最终输出层\n",
    "        self.final_conv = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "        # 权重初始化\n",
    "        self._initialize_weights()\n",
    "\n",
    "        # 加载预训练权重（可选）\n",
    "        if pretrained:\n",
    "            self._load_pretrained_weights()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \"\"\"构建ResNet的层级\"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_decoder_block(self, in_channels, out_channels):\n",
    "        \"\"\"构建解码器块\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"初始化权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _load_pretrained_weights(self):\n",
    "        \"\"\"加载预训练的ResNet50权重\"\"\"\n",
    "        try:\n",
    "            pretrained_state_dict = model_zoo.load_url(\n",
    "                'https://download.pytorch.org/models/resnet50-19c8e357.pth'\n",
    "            )\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in pretrained_state_dict.items() if k in model_dict}\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "            print(\"成功加载ImageNet预训练权重\")\n",
    "        except Exception as e:\n",
    "            print(f\"警告: 加载预训练权重失败: {e}\")\n",
    "\n",
    "    def forward(self, x, size=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "\n",
    "        Args:\n",
    "            x: 输入图像 [B, 3, H, W]\n",
    "            size: 目标输出尺寸 (H_target, W_target)，默认为None时使用scale_factor=4\n",
    "        \"\"\"\n",
    "        # 编码器部分\n",
    "        x0 = self.conv1(x)           # [B, 64, H/2, W/2]\n",
    "        x0 = self.bn1(x0)\n",
    "        x0 = self.relu(x0)\n",
    "        x0 = self.maxpool(x0)        # [B, 64, H/4, W/4]\n",
    "\n",
    "        # Layer1 + CBAM\n",
    "        x1 = self.layer1(x0)         # [B, 256, H/4, W/4]\n",
    "        x1 = self.cbam1(x1)\n",
    "\n",
    "        # Layer2 + CBAM\n",
    "        x2 = self.layer2(x1)         # [B, 512, H/8, W/8]\n",
    "        x2 = self.cbam2(x2)\n",
    "\n",
    "        # Layer3 + CBAM\n",
    "        x3 = self.layer3(x2)         # [B, 1024, H/16, W/16]\n",
    "        x3 = self.cbam3(x3)\n",
    "\n",
    "        # Layer4 + CBAM\n",
    "        x4 = self.layer4(x3)         # [B, 2048, H/32, W/32]\n",
    "        x4 = self.cbam4(x4)\n",
    "\n",
    "        # 解码器部分\n",
    "        # 1/32 -> 1/16\n",
    "        h, w = x3.shape[2], x3.shape[3]\n",
    "        x = F.interpolate(x4, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.decoder4(x)         # [B, 256, H/16, W/16]\n",
    "\n",
    "        # 1/16 -> 1/8\n",
    "        h, w = x2.shape[2], x2.shape[3]\n",
    "        x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.decoder3(x)         # [B, 128, H/8, W/8]\n",
    "\n",
    "        # 1/8 -> 1/4\n",
    "        h, w = x1.shape[2], x1.shape[3]\n",
    "        x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.decoder2(x)         # [B, 64, H/4, W/4]\n",
    "\n",
    "        # 1/4 -> 1/2\n",
    "        h, w = x0.shape[2], x0.shape[3]\n",
    "        x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, x0], dim=1)\n",
    "        x = self.decoder1(x)         # [B, 32, H/4, W/4]\n",
    "\n",
    "        # 最终卷积\n",
    "        x = self.final_conv(x)       # [B, num_classes, H/4, W/4]\n",
    "\n",
    "        # 最终上采样到原始尺寸\n",
    "        if size is not None:\n",
    "            target_h, target_w = size\n",
    "            output = F.interpolate(x, size=(target_h, target_w), mode='bilinear', align_corners=False)\n",
    "        else:\n",
    "            output = F.interpolate(x, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def resnet50_cbam_segmentation(num_classes=19, pretrained=False):\n",
    "    \"\"\"创建ResNet50+CBAM语义分割模型\"\"\"\n",
    "    return ResNet50CBAM_Segmentation(\n",
    "        Bottleneck, [3, 4, 6, 3],\n",
    "        num_classes=num_classes,\n",
    "        pretrained=pretrained\n",
    "    )\n",
    "#==================== ResNet50+CBAM语义分割模型完 ===================="
   ],
   "id": "933836dc6c026db4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:22:26.851975400Z",
     "start_time": "2025-12-24T07:48:36.849965200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ==================== Cityscapes数据集加载 ====================\n",
    "class CityscapesDataset(Dataset):\n",
    "    \"\"\"Cityscapes语义分割数据集\"\"\"\n",
    "    CLASSES = [\n",
    "        'road', 'sidewalk', 'building', 'wall', 'fence', 'pole',\n",
    "        'traffic light', 'traffic sign', 'vegetation', 'terrain',\n",
    "        'sky', 'person', 'rider', 'car', 'truck', 'bus', 'train',\n",
    "        'motorcycle', 'bicycle'\n",
    "    ]\n",
    "\n",
    "    # 19类别的颜色映射 (RGB格式)\n",
    "    CLASS_COLORS = {\n",
    "        0: [128, 64, 128],     # road - 紫色\n",
    "        1: [244, 35, 232],     # sidewalk - 粉色\n",
    "        2: [70, 70, 70],       # building - 深灰\n",
    "        3: [102, 102, 156],    # wall - 蓝灰\n",
    "        4: [190, 153, 153],    # fence - 棕灰\n",
    "        5: [153, 153, 153],    # pole - 灰\n",
    "        6: [250, 170, 30],     # traffic light - 橙色\n",
    "        7: [220, 220, 0],      # traffic sign - 黄色\n",
    "        8: [107, 142, 35],     # vegetation - 绿色\n",
    "        9: [152, 251, 152],    # terrain - 浅绿\n",
    "        10: [70, 130, 180],    # sky - 天蓝\n",
    "        11: [220, 20, 60],     # person - 红色\n",
    "        12: [255, 0, 0],       # rider - 深红\n",
    "        13: [0, 0, 142],       # car - 蓝色\n",
    "        14: [0, 0, 70],        # truck - 深蓝\n",
    "        15: [0, 60, 100],      # bus - 藏青\n",
    "        16: [0, 80, 100],      # train - 青蓝\n",
    "        17: [0, 0, 230],       # motorcycle - 靛蓝\n",
    "        18: [119, 11, 32],     # bicycle - 紫红\n",
    "        255: [0, 0, 0],        # ignore - 黑\n",
    "    }\n",
    "\n",
    "    LABEL_ID_MAPPING = {\n",
    "        7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5, 19: 6, 20: 7, 21: 8,\n",
    "        22: 9, 23: 10, 24: 11, 25: 12, 26: 13, 27: 14, 28: 15,\n",
    "        31: 16, 32: 17, 33: 18,\n",
    "    }\n",
    "\n",
    "    def __init__(self, root, split='train', transform=None, target_size=(1024, 512)):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "\n",
    "        self.images = self._get_image_paths()\n",
    "        self.targets = self._get_target_paths()\n",
    "\n",
    "        print(f\"Cityscapes {split} set: {len(self.images)} images\")\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        \"\"\"获取所有图像路径\"\"\"\n",
    "        image_dir = os.path.join(self.root, 'leftImg8bit', self.split)\n",
    "        images = []\n",
    "\n",
    "        for city in os.listdir(image_dir):\n",
    "            city_dir = os.path.join(image_dir, city)\n",
    "            for img_name in os.listdir(city_dir):\n",
    "                if img_name.endswith('_leftImg8bit.png'):\n",
    "                    images.append(os.path.join(city_dir, img_name))\n",
    "\n",
    "        return sorted(images)\n",
    "\n",
    "    def _get_target_paths(self):\n",
    "        \"\"\"获取所有标注路径\"\"\"\n",
    "        target_dir = os.path.join(self.root, 'gtFine', self.split)\n",
    "        targets = []\n",
    "\n",
    "        for img_path in self.images:\n",
    "            img_name = os.path.basename(img_path)\n",
    "            base_name = img_name.replace('_leftImg8bit.png', '')\n",
    "            city = os.path.basename(os.path.dirname(img_path))\n",
    "            target_name = f'{base_name}_gtFine_labelIds.png'\n",
    "            target_path = os.path.join(target_dir, city, target_name)\n",
    "            targets.append(target_path)\n",
    "\n",
    "        return sorted(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取单个样本\"\"\"\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        target = Image.open(self.targets[idx])\n",
    "\n",
    "        # 保存原始尺寸\n",
    "        original_size = image.size[::-1]  # (height, width)\n",
    "\n",
    "        # 调整尺寸（用于训练）\n",
    "        image = image.resize(self.target_size, Image.BILINEAR)\n",
    "        target = target.resize(self.target_size, Image.NEAREST)\n",
    "\n",
    "        # 应用增强\n",
    "        if self.transform:\n",
    "            image, target = self.transform(image, target)\n",
    "\n",
    "        # 转换为张量\n",
    "        image = torch.from_numpy(np.array(image)).permute(2, 0, 1).float() / 255.0\n",
    "        target = self._remap_labels(np.array(target))\n",
    "\n",
    "        return image, target, original_size, self.images[idx]\n",
    "\n",
    "    def _remap_labels(self, target):\n",
    "        \"\"\"将原始标签ID映射到类别索引\"\"\"\n",
    "        remapped = np.full_like(target, 255)\n",
    "        for old_id, new_id in self.LABEL_ID_MAPPING.items():\n",
    "            remapped[target == old_id] = new_id\n",
    "        return torch.from_numpy(remapped).long()\n",
    "\n",
    "\n",
    "class SimpleTransform:\n",
    "    \"\"\"简单的数据增强\"\"\"\n",
    "\n",
    "    def __init__(self, crop_size=(512, 512), flip_prob=0.5):\n",
    "        self.crop_size = crop_size\n",
    "        self.flip_prob = flip_prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        # 随机水平翻转\n",
    "        if random.random() < self.flip_prob:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            target = target.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        # 随机裁剪\n",
    "        crop_width, crop_height = self.crop_size\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        left = random.randint(0, image_width - crop_width)\n",
    "        top = random.randint(0, image_height - crop_height)\n",
    "\n",
    "        image = image.crop((left, top, left + crop_width, top + crop_height))\n",
    "        target = target.crop((left, top, left + crop_width, top + crop_height))\n",
    "\n",
    "        # 确保返回的是PIL Image\n",
    "        if not isinstance(image, Image.Image):\n",
    "            image = Image.fromarray(np.array(image))\n",
    "        if not isinstance(target, Image.Image):\n",
    "            target = Image.fromarray(np.array(target))\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "# ==================== 损失函数 ====================\n",
    "\n",
    "class SegmentationLoss(nn.Module):\n",
    "    \"\"\"交叉熵损失函数\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=19, ignore_index=255, weight=None):\n",
    "        super(SegmentationLoss, self).__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_index,\n",
    "            reduction='mean'\n",
    "        )\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.contiguous()\n",
    "        target = target.contiguous()\n",
    "        loss = self.criterion(pred, target)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice损失函数\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=19, ignore_index=255, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        num_classes = pred.shape[1]\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "\n",
    "        total_loss = 0\n",
    "        for cls in range(num_classes):\n",
    "            pred_cls = pred[:, cls, :, :]\n",
    "            target_cls = (target == cls).float()\n",
    "\n",
    "            valid_mask = (target != self.ignore_index)\n",
    "            pred_cls = pred_cls * valid_mask\n",
    "            target_cls = target_cls * valid_mask\n",
    "\n",
    "            intersection = (pred_cls * target_cls).sum()\n",
    "            dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
    "                pred_cls.sum() + target_cls.sum() + self.smooth\n",
    "            )\n",
    "            total_loss += dice_loss\n",
    "\n",
    "        return total_loss / num_classes\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"组合损失函数（CE + Dice）\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=19, ignore_index=255, ce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.ce_loss = SegmentationLoss(num_classes, ignore_index)\n",
    "        self.dice_loss = DiceLoss(num_classes, ignore_index)\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        return self.ce_weight * ce + self.dice_weight * dice\n",
    "\n",
    "\n",
    "# ==================== 可视化工具函数 ====================\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses, save_path='loss_curve.png'):\n",
    "    \"\"\"\n",
    "    绘制并保存loss曲线\n",
    "\n",
    "    Args:\n",
    "        train_losses: 训练loss列表\n",
    "        val_losses: 验证loss列表\n",
    "        save_path: 保存路径\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # 训练loss曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Training Loss Curve', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 验证loss曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Val Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Validation Loss Curve', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Loss曲线已保存至: {save_path}\")\n",
    "\n",
    "\n",
    "def create_overlay_image(original_image, prediction, alpha=0.25):\n",
    "    \"\"\"\n",
    "    将分割结果以指定透明度叠加到原始图像上\n",
    "\n",
    "    Args:\n",
    "        original_image: 原始图像 (PIL Image)\n",
    "        prediction: 分割预测结果 (numpy数组, H, W)\n",
    "        alpha: 叠加透明度 (0-1之间)，默认0.25表示25%透明度\n",
    "\n",
    "    Returns:\n",
    "        overlayed_image: 叠加后的PIL Image\n",
    "    \"\"\"\n",
    "    # 调整预测结果尺寸以匹配原始图像\n",
    "    orig_w, orig_h = original_image.size\n",
    "    prediction_resized = np.array(Image.fromarray(prediction.astype(np.uint16)).resize(\n",
    "        (orig_w, orig_h), Image.NEAREST\n",
    "    ))\n",
    "\n",
    "    # 创建彩色分割掩码\n",
    "    h, w = prediction_resized.shape\n",
    "    colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in CityscapesDataset.CLASS_COLORS.items():\n",
    "        if class_id != 255:\n",
    "            colored_mask[prediction_resized == class_id] = color\n",
    "\n",
    "    mask_image = Image.fromarray(colored_mask)\n",
    "\n",
    "    # 使用PIL的blend函数进行25%透明度叠加\n",
    "    overlayed_image = Image.blend(original_image, mask_image, alpha=alpha)\n",
    "\n",
    "    return overlayed_image\n",
    "\n",
    "\n",
    "# ==================== 增强的训练器 ====================\n",
    "\n",
    "class SegmentationTrainer:\n",
    "    \"\"\"语义分割训练器 - 增强版（包含Loss保存和模型保存）\"\"\"\n",
    "\n",
    "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, scheduler, device,\n",
    "                 save_dir='checkpoints'):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "\n",
    "        # 创建保存目录\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Loss记录\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_miou_history = []\n",
    "\n",
    "        self.best_miou = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"训练一个epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, (images, targets, _, _) in enumerate(self.train_loader):\n",
    "            images = images.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "\n",
    "            outputs = self.model(images, size=None)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 反向传播\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f\"  Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        \"\"\"验证\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        confusion_matrix = np.zeros((19, 19))\n",
    "\n",
    "        for images, targets, _, _ in self.val_loader:\n",
    "            images = images.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "\n",
    "            outputs = self.model(images, size=None)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            for t, p in zip(targets.cpu().numpy(), preds.cpu().numpy()):\n",
    "                for gt, pred in zip(t.flatten(), p.flatten()):\n",
    "                    if gt != 255:\n",
    "                        confusion_matrix[gt, pred] += 1\n",
    "\n",
    "        intersection = np.diag(confusion_matrix)\n",
    "        union = confusion_matrix.sum(axis=1) + confusion_matrix.sum(axis=0) - intersection\n",
    "        iou = intersection / (union + 1e-10)\n",
    "        miou = np.mean(iou[iou > 0])\n",
    "\n",
    "        return total_loss / len(self.val_loader), miou\n",
    "\n",
    "    def save_loss_history(self, filename='loss_history.json'):\n",
    "        \"\"\"保存loss历史记录到JSON文件\"\"\"\n",
    "        history = {\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_miou_history': self.val_miou_history\n",
    "        }\n",
    "        filepath = os.path.join(self.save_dir, filename)\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "        print(f\"Loss历史记录已保存至: {filepath}\")\n",
    "\n",
    "    def save_final_model(self, filename='final_model.pth'):\n",
    "        \"\"\"保存最终模型参数\"\"\"\n",
    "        filepath = os.path.join(self.save_dir, filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'best_miou': self.best_miou\n",
    "        }, filepath)\n",
    "        print(f\"最终模型已保存至: {filepath}\")\n",
    "        return filepath\n",
    "\n",
    "    def train(self, num_epochs, save_path='best_model.pth'):\n",
    "        \"\"\"完整训练流程\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"开始训练 ResNet50+CBAM 语义分割模型\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 完整的保存路径\n",
    "        best_model_path = os.path.join(self.save_dir, save_path)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.epoch = epoch\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_miou = self.validate()\n",
    "\n",
    "            # 记录loss\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_miou_history.append(val_miou)\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, mIoU: {val_miou:.4f}\")\n",
    "\n",
    "            if val_miou > self.best_miou:\n",
    "                self.best_miou = val_miou\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'miou': val_miou\n",
    "                }, best_model_path)\n",
    "                print(f\"保存最佳模型！mIoU: {val_miou:.4f}\")\n",
    "\n",
    "            # 每5个epoch保存一次loss历史\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                self.save_loss_history()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"训练完成！开始保存最终结果...\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 保存最终模型\n",
    "        self.save_final_model('final_model.pth')\n",
    "\n",
    "        # 绘制并保存loss曲线\n",
    "        loss_curve_path = os.path.join(self.save_dir, 'loss_curve.png')\n",
    "        plot_loss_curve(self.train_losses, self.val_losses, save_path=loss_curve_path)\n",
    "\n",
    "        # 最终保存loss历史\n",
    "        self.save_loss_history()\n",
    "\n",
    "        print(f\"\\n训练完成！最佳mIoU: {self.best_miou:.4f}\")\n",
    "        return self.best_miou\n",
    "\n",
    "\n",
    "# ==================== 测试和可视化函数 ====================\n",
    "\n",
    "def test_and_visualize(model, data_loader, device, save_dir='test_results', num_samples=20):\n",
    "    \"\"\"\n",
    "    测试模型并可视化分割结果\n",
    "\n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        data_loader: 数据加载器\n",
    "        device: 设备\n",
    "        save_dir: 保存目录\n",
    "        num_samples: 可视化样本数量\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"开始生成测试可视化结果...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 创建保存目录\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    overlayed_dir = os.path.join(save_dir, 'overlayed_results')\n",
    "    mask_dir = os.path.join(save_dir, 'segmentation_masks')\n",
    "    os.makedirs(overlayed_dir, exist_ok=True)\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_iou = []\n",
    "    sample_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets, original_sizes, image_paths in data_loader:\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images, size=None)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            for i in range(min(batch_size, num_samples - sample_count)):\n",
    "                # 获取原始图像\n",
    "                original_img = np.clip(images[i].cpu().permute(1, 2, 0).numpy() * 255, 0, 255).astype(np.uint8)\n",
    "                original_pil = Image.fromarray(original_img)\n",
    "\n",
    "                # 获取预测结果\n",
    "                pred = preds[i].cpu().numpy()\n",
    "                target = targets[i].numpy()\n",
    "\n",
    "                # 获取原始尺寸\n",
    "                orig_h = original_sizes[0][i].item()\n",
    "                orig_w = original_sizes[1][i].item()\n",
    "\n",
    "                # 计算该样本的IoU\n",
    "                valid_mask = (target != 255) & (pred != 255)\n",
    "                if valid_mask.sum() > 0:\n",
    "                    intersection = ((pred == target) & valid_mask).sum()\n",
    "                    union = valid_mask.sum()\n",
    "                    iou = intersection / (union + 1e-10)\n",
    "                    total_iou.append(iou)\n",
    "\n",
    "                # 创建彩色分割掩码\n",
    "                pred_resized = np.array(Image.fromarray(pred.astype(np.uint16)).resize(\n",
    "                    (orig_w, orig_h), Image.NEAREST\n",
    "                ))\n",
    "\n",
    "                colored_mask = np.zeros((orig_h, orig_w, 3), dtype=np.uint8)\n",
    "                for class_id, color in CityscapesDataset.CLASS_COLORS.items():\n",
    "                    if class_id != 255:\n",
    "                        colored_mask[pred_resized == class_id] = color\n",
    "                mask_pil = Image.fromarray(colored_mask)\n",
    "\n",
    "                # 保存分割掩码\n",
    "                mask_filename = f'sample_{sample_count + 1:04d}_mask.png'\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "                mask_pil.save(mask_path)\n",
    "\n",
    "                # 创建25%透明度叠加图像\n",
    "                original_pil_resized = original_pil.resize((orig_w, orig_h), Image.BILINEAR)\n",
    "                mask_resized = mask_pil.resize((orig_w, orig_h), Image.NEAREST)\n",
    "                overlayed = Image.blend(original_pil_resized, mask_resized, alpha=0.25)\n",
    "\n",
    "                # 保存叠加结果\n",
    "                overlay_filename = f'sample_{sample_count + 1:04d}_overlay.png'\n",
    "                overlayed_path = os.path.join(overlayed_dir, overlay_filename)\n",
    "                overlayed.save(overlayed_path)\n",
    "\n",
    "                # 获取原始图像文件名\n",
    "                original_filename = os.path.basename(image_paths[i])\n",
    "                iou_value = total_iou[-1] if total_iou else 0\n",
    "\n",
    "                print(f\"样本 {sample_count + 1}: IoU={iou_value:.4f}\")\n",
    "                print(f\"  - 原始图像: {original_filename}\")\n",
    "                print(f\"  - 分割掩码: {mask_path}\")\n",
    "                print(f\"  - 叠加图像(25%透明度): {overlayed_path}\")\n",
    "\n",
    "                sample_count += 1\n",
    "\n",
    "    # 保存测试报告\n",
    "    if total_iou:\n",
    "        avg_iou = np.mean(total_iou)\n",
    "        report = {\n",
    "            'num_samples': len(total_iou),\n",
    "            'average_iou': float(avg_iou),\n",
    "            'iou_list': [float(iou) for iou in total_iou],\n",
    "            'save_dir': save_dir\n",
    "        }\n",
    "        report_path = os.path.join(save_dir, 'test_report.json')\n",
    "        with open(report_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"\\n测试报告已保存至: {report_path}\")\n",
    "        print(f\"平均IoU: {avg_iou:.4f}\")\n",
    "\n",
    "    print(f\"\\n测试完成！共生成 {sample_count} 个可视化样本\")\n",
    "    print(f\"分割掩码保存在: {mask_dir}\")\n",
    "    print(f\"叠加结果保存在: {overlayed_dir}\")\n",
    "\n",
    "\n",
    "# ==================== 训练配置和启动 ====================\n",
    "\n",
    "def setup_training(data_root, batch_size=8, num_classes=19, learning_rate=1e-4,\n",
    "                   num_epochs=50, num_workers=0, save_dir='checkpoints'):\n",
    "    \"\"\"配置并启动训练\"\"\"\n",
    "\n",
    "    # 设备配置\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "\n",
    "    # 检查GPU状态\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "    # 创建数据集\n",
    "    train_transform = SimpleTransform(crop_size=(512, 512))\n",
    "\n",
    "    train_dataset = CityscapesDataset(\n",
    "        root=data_root,\n",
    "        split='train',\n",
    "        transform=train_transform,\n",
    "        target_size=(1024, 512)\n",
    "    )\n",
    "\n",
    "    val_dataset = CityscapesDataset(\n",
    "        root=data_root,\n",
    "        split='val',\n",
    "        target_size=(1024, 512)\n",
    "    )\n",
    "\n",
    "    # 创建数据加载器（Windows环境使用num_workers=0）\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # 创建模型\n",
    "    print(\"\\n创建模型...\")\n",
    "    model = resnet50_cbam_segmentation(\n",
    "        num_classes=num_classes,\n",
    "        pretrained=True\n",
    "    ).to(device)\n",
    "\n",
    "    # 统计参数\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"总参数数量: {total_params:,}\")\n",
    "    print(f\"可训练参数: {trainable_params:,}\")\n",
    "\n",
    "    # 创建损失函数和优化器\n",
    "    criterion = CombinedLoss(num_classes=num_classes)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.PolynomialLR(\n",
    "        optimizer, total_iters=len(train_loader) * num_epochs, power=0.9\n",
    "    )\n",
    "\n",
    "    # 创建训练器（添加save_dir参数）\n",
    "    trainer = SegmentationTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        save_dir=save_dir\n",
    "    )\n",
    "\n",
    "    # 开始训练\n",
    "    best_miou = trainer.train(num_epochs=num_epochs)\n",
    "\n",
    "    print(f\"\\n最终结果:\")\n",
    "    print(f\"  最佳验证mIoU: {best_miou:.4f}\")\n",
    "\n",
    "    return model, trainer\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数 - 增强版\"\"\"\n",
    "    # 配置参数（请修改为您的实际路径）\n",
    "    data_root = \"E:\\\\Laboratory files\\\\code_project\\\\city_data\"  # 您的Cityscapes数据集路径 E:\\Laboratory files\\code_project\\city_data\\leftImg8bit\\train\\aachen\n",
    "    batch_size = 4  # 根据您的GPU显存调整\n",
    "    num_classes = 19\n",
    "    learning_rate = 1e-4\n",
    "    num_epochs = 50\n",
    "    num_workers = 0  # Windows环境必须设置为0\n",
    "    save_dir = 'checkpoints'  # 模型和loss保存目录\n",
    "    test_samples = 20  # 测试时可视化的样本数量\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ResNet50+CBAM 语义分割训练 - 增强版\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"数据路径: {data_root}\")\n",
    "    print(f\"批次大小: {batch_size}\")\n",
    "    print(f\"学习率: {learning_rate}\")\n",
    "    print(f\"训练轮数: {num_epochs}\")\n",
    "    print(f\"模型保存目录: {save_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 创建模型目录\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 训练\n",
    "    model, trainer = setup_training(\n",
    "        data_root=data_root,\n",
    "        batch_size=batch_size,\n",
    "        num_classes=num_classes,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        num_workers=num_workers,\n",
    "        save_dir=save_dir\n",
    "    )\n",
    "\n",
    "    # 训练完成后自动进行测试和可视化\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"训练完成，开始生成测试可视化结果...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 使用验证集进行测试可视化\n",
    "    test_dataset = CityscapesDataset(\n",
    "        root=data_root,\n",
    "        split='val',\n",
    "        target_size=(1024, 512)\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,  # 测试时使用batch_size=1便于逐个处理\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    # 测试并可视化\n",
    "    test_and_visualize(\n",
    "        model=model,\n",
    "        data_loader=test_loader,\n",
    "        device=next(model.parameters()).device,\n",
    "        save_dir='test_results',\n",
    "        num_samples=test_samples\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"所有任务完成！\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"最佳模型: {os.path.join(save_dir, 'best_model.pth')}\")\n",
    "    print(f\"最终模型: {os.path.join(save_dir, 'final_model.pth')}\")\n",
    "    print(f\"Loss历史: {os.path.join(save_dir, 'loss_history.json')}\")\n",
    "    print(f\"Loss曲线: {os.path.join(save_dir, 'loss_curve.png')}\")\n",
    "    print(f\"测试结果: test_results/overlayed_results/\")\n",
    "\n",
    "    return model, trainer\n",
    "\n",
    "\n",
    "# Windows环境必须添加的保护\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"训练过程中出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ],
   "id": "fa8752b9f4949eb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ResNet50+CBAM 语义分割训练 - 增强版\n",
      "============================================================\n",
      "数据路径: E:\\Laboratory files\\code_project\\city_data\n",
      "批次大小: 4\n",
      "学习率: 0.0001\n",
      "训练轮数: 50\n",
      "模型保存目录: checkpoints\n",
      "============================================================\n",
      "使用设备: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU显存: 8.00 GB\n",
      "Cityscapes train set: 2975 images\n",
      "Cityscapes val set: 500 images\n",
      "\n",
      "创建模型...\n",
      "成功加载ImageNet预训练权重\n",
      "总参数数量: 33,212,283\n",
      "可训练参数: 33,212,283\n",
      "============================================================\n",
      "开始训练 ResNet50+CBAM 语义分割模型\n",
      "============================================================\n",
      "\n",
      "Epoch 1/50\n",
      "----------------------------------------\n",
      "  Batch 0/744, Loss: 2.2540\n",
      "  Batch 50/744, Loss: 1.1985\n",
      "  Batch 100/744, Loss: 0.9604\n",
      "  Batch 150/744, Loss: 0.6952\n",
      "  Batch 200/744, Loss: 0.6556\n",
      "  Batch 250/744, Loss: 0.8347\n",
      "  Batch 300/744, Loss: 0.6427\n",
      "  Batch 350/744, Loss: 0.7070\n",
      "  Batch 400/744, Loss: 0.6840\n",
      "  Batch 450/744, Loss: 0.5325\n",
      "  Batch 500/744, Loss: 0.6236\n",
      "  Batch 550/744, Loss: 0.5988\n",
      "  Batch 600/744, Loss: 0.5086\n",
      "  Batch 650/744, Loss: 0.5077\n",
      "  Batch 700/744, Loss: 0.4893\n",
      "Train Loss: 0.7231\n",
      "Val Loss: 0.5672, mIoU: 0.3869\n",
      "保存最佳模型！mIoU: 0.3869\n",
      "\n",
      "Epoch 2/50\n",
      "----------------------------------------\n",
      "  Batch 0/744, Loss: 0.5440\n",
      "  Batch 50/744, Loss: 0.4544\n",
      "  Batch 100/744, Loss: 0.5476\n",
      "  Batch 150/744, Loss: 0.4972\n",
      "  Batch 200/744, Loss: 0.4566\n",
      "  Batch 250/744, Loss: 0.5249\n",
      "  Batch 300/744, Loss: 0.5360\n",
      "  Batch 350/744, Loss: 0.5833\n",
      "  Batch 400/744, Loss: 0.5657\n",
      "  Batch 450/744, Loss: 0.4394\n",
      "  Batch 500/744, Loss: 0.4581\n",
      "  Batch 550/744, Loss: 0.4578\n",
      "  Batch 600/744, Loss: 0.4715\n",
      "  Batch 650/744, Loss: 0.4849\n",
      "  Batch 700/744, Loss: 0.4503\n",
      "Train Loss: 0.4889\n",
      "Val Loss: 0.4669, mIoU: 0.4786\n",
      "保存最佳模型！mIoU: 0.4786\n",
      "\n",
      "Epoch 3/50\n",
      "----------------------------------------\n",
      "  Batch 0/744, Loss: 0.4107\n",
      "  Batch 50/744, Loss: 0.4598\n",
      "  Batch 100/744, Loss: 0.4665\n",
      "  Batch 150/744, Loss: 0.4244\n",
      "  Batch 200/744, Loss: 0.5945\n",
      "  Batch 250/744, Loss: 0.4427\n",
      "  Batch 300/744, Loss: 0.3613\n",
      "  Batch 350/744, Loss: 0.5668\n",
      "  Batch 400/744, Loss: 0.3964\n",
      "  Batch 450/744, Loss: 0.3892\n",
      "  Batch 500/744, Loss: 0.4474\n",
      "  Batch 550/744, Loss: 0.4210\n",
      "  Batch 600/744, Loss: 0.3633\n",
      "  Batch 650/744, Loss: 0.4538\n",
      "  Batch 700/744, Loss: 0.5811\n",
      "Train Loss: 0.4313\n",
      "Val Loss: 0.4287, mIoU: 0.5152\n",
      "保存最佳模型！mIoU: 0.5152\n",
      "\n",
      "Epoch 4/50\n",
      "----------------------------------------\n",
      "  Batch 0/744, Loss: 0.3790\n",
      "  Batch 50/744, Loss: 0.4235\n",
      "  Batch 100/744, Loss: 0.4297\n",
      "  Batch 150/744, Loss: 0.3232\n",
      "  Batch 200/744, Loss: 0.3731\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "edc403b1f5e89e9a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
