{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "ResNet50 + CBAM 网络结构核心代码\n",
    "保留了CBAM注意力机制和ResNet50的完整实现\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "__all__ = ['ResNet', 'resnet50_cbam']\n",
    "\n",
    "model_urls = {'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n"
   ],
   "id": "1bb6819b6a958ad3",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CBAM模块代码",
   "id": "eb9c037426d81337"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CBAM的通道注意力和空间注意力模块\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"通道注意力模块\"\"\"\n",
    "\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"空间注意力模块\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)"
   ],
   "id": "1a06c763cb2bf5bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Resnet50核心模块",
   "id": "9b5bcbb8d14b70ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Resnet模块\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet50的瓶颈块，集成CBAM注意力机制\"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # CBAM注意力模块\n",
    "        self.ca = ChannelAttention(planes * 4)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # 应用CBAM注意力机制\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"完整的ResNet网络结构，集成CBAM注意力机制\"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet的各个层\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # 权重初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \"\"\"构建ResNet的层级\"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 2048)\n",
    "        x = self.fc(x)  # (batch_size, num_classes)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"\n",
    "    创建预训练的ResNet50+CBAM模型\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): 如果为True，返回在ImageNet上预训练的模型\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: ResNet50+CBAM模型\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        # 加载预训练的ResNet50权重\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet50']) # 这一步会将pth的权重下载到\"C:\\Users\\GaoZixian\\.cache\\torch\\hub\\checkpoints\\\"\n",
    "        now_state_dict = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建模型\n",
    "    model = resnet50_cbam(pretrained=True)\n",
    "\n",
    "    # 测试模型\n",
    "    batch_size = 4\n",
    "    input_tensor = torch.randn(batch_size, 3, 224, 224)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    print(f\"输入形状: {input_tensor.shape}\")\n",
    "    print(f\"输出形状: {output.shape}\")\n",
    "    print(f\"模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "id": "74ac0ad5433ad8bf"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
